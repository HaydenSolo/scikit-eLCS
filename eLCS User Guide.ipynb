{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eLCS Complete User Guide\n",
    "\n",
    "Author: Robert Zhang - University of Pennsylvania, B.S.E Computer Science, B.S.E. Economics (SEAS '22, WH '22)\n",
    "\n",
    "Advisor: Ryan Urbanowicz, PhD - University of Pennsylvania, Department of Biostatics, Epidemiology, and Informatics & Institue for Biomedical Informatics (IBI)\n",
    "\n",
    "Date: 02/24/2020\n",
    "\n",
    "Requirements: Anaconda (with Python 3)\n",
    "<ul>\n",
    "    <li>Install most recent version of Anaconda</li>\n",
    "</ul>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook presents a complete user guide to the eLCS scikit-learn package as well as auxilliary helper objects. eLCS is a supervised learning variant of the Learning Classifier System. In general, Learning Classifier Systems (LCSs) are a classification of Rule Based Machine Learning Algorithms that have been shown to perform well on problems involving high amounts of heterogeneity and epistasis. Well designed LCSs are also highly human interpretable. LCS variants have been shown to adeptly handle supervised and reinforced, classification and regression, online and offline learning problems, as well as missing or unbalanced data. These characteristics of versatility and interpretability give LCSs a wide range of potential applications, notably those in biomedicine. This package is still under active development and we encourage you to check back on this repository for updates.\n",
    "\n",
    "eLCS, or Educational Learning Classifier System, implements the core components of a Michigan-Style Learning Classifier System (where the system's genetic algorithm operates on a rule level, evolving a population of rules with each their own parameters) in an easy to understand way, while still being highly functional in solving ML problems.\n",
    "\n",
    "While Learning Classifier Systems are commonly applied to genetic analyses, where epistatis (i.e. feature interactions) is common, the eLCS algorithm implemented in this package can be applied to almost any supervised classification data set and supports:\n",
    "\n",
    "<ul>\n",
    "    <li>Feature sets that are discrete/categorical, continuous-valued or a mix of both</li>\n",
    "    <li>Data with missing values</li>\n",
    "    <li>Binary Classification Problems (Binary Endpoints)</li>\n",
    "    <li>Multi-class Classification Problems (Multi-class Endpoints)</li>\n",
    "</ul>\n",
    "\n",
    "It is important to mention that the eLCS package does not currently support regression problems (continuous endpoints). Regression functionality is built into the package. However, we have decided to disable it for this version, since eLCS performs best on purely classification problems.\n",
    "\n",
    "## Notebook Organization\n",
    "\n",
    "**Part 1: Loading Data**\n",
    "<ul>\n",
    "    <li> Dataset format requirements for eLCS</li>\n",
    "    <li> Method 1: Loading data using pandas</li>\n",
    "    <li> Method 2: Loading data using StringEnumerator</li>\n",
    "</ul>\n",
    "\n",
    "**Part 2: Initializing scikit-learn eLCS Classifier Object**\n",
    "<ul>\n",
    "    <li> Basic Initialization</li>\n",
    "    <li> Overview of all eLCS initialization parameters and default values</li>\n",
    "</ul>\n",
    "\n",
    "**Part 3: Model Training and Testing**\n",
    "<ul>\n",
    "    <li> model.fit(X,y) and how it works</li>\n",
    "    <li> model.predict(X), model.predict_proba(X) and model.score(X,y)</li>\n",
    "    <li> model Cross Validation and Scoring</li>\n",
    "    <li> model.predict_proba(x) and ROC/AUC/PRC curves </li>\n",
    "</ul>\n",
    "\n",
    "**Part 4: Data Collection and Export**\n",
    "<ul>\n",
    "    <li> evalWhileFit, trackingFrequency, learningCheckpoints </li>\n",
    "    <li> Exporting and Accessing Iteration Tracking Data </li>\n",
    "    <li> Exporting and Accessing Rule Population Data </li>\n",
    "</ul>\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data\n",
    "\n",
    "### Dataset Format Requirement for eLCS\n",
    "\n",
    "There are 4 requirements for the dataset:\n",
    "<ul>\n",
    "    <li>Data Attributes for all data instances are represented by an <b>nxm</b> numpy.ndarray, where <b>n</b> = # of instances and <b>m</b> = # of attributes for each instance</li>\n",
    "    <li>Data Phenotypes for all data instances are represented by a 1 dimensional numpy.ndarray of length <b>n</b></li>\n",
    "    <li>Both the <b>nxm</b> attribute array and the length <b>n</b> phenotype array are fully numeric. This means that every element in each array must be convertable to a float. String, boolean types are not permitted (of course, boolean datasets can be represented by binary 0s and 1s). It is important to mention that missing data in the attribute dataset is acceptable, if represented as a NaN type within the array. Missing data in the phenotype array is not acceptable.</li>\n",
    "    <li>As mentioned aboved, the problem must be a classification problem. This version does not support regression problems.</li>\n",
    "</ul>\n",
    "\n",
    "The package includes automated parameter checking that will raise an Exception at the start of training if the dataset does not meet the above requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data Method 1: Using pandas\n",
    "\n",
    "There are many ways you can derive the attribute and phenotype array. One most common method is by using pandas via reading from a csv file, as the below code demonstrates with the a 6 bit multiplexer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 1 0 1 0]\n",
      " [0 0 1 0 1 1]\n",
      " [0 0 1 1 0 0]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 1]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 1 1]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 0 1 0 1]\n",
      " [0 1 0 1 1 0]\n",
      " [0 1 0 1 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 1 0 0 1]\n",
      " [0 1 1 0 1 0]\n",
      " [0 1 1 0 1 1]\n",
      " [0 1 1 1 0 0]\n",
      " [0 1 1 1 0 1]\n",
      " [0 1 1 1 1 0]\n",
      " [0 1 1 1 1 1]\n",
      " [1 0 0 0 0 0]\n",
      " [1 0 0 0 0 1]\n",
      " [1 0 0 0 1 0]\n",
      " [1 0 0 0 1 1]\n",
      " [1 0 0 1 0 0]\n",
      " [1 0 0 1 0 1]\n",
      " [1 0 0 1 1 0]\n",
      " [1 0 0 1 1 1]\n",
      " [1 0 1 0 0 0]\n",
      " [1 0 1 0 0 1]\n",
      " [1 0 1 0 1 0]\n",
      " [1 0 1 0 1 1]\n",
      " [1 0 1 1 0 0]\n",
      " [1 0 1 1 0 1]\n",
      " [1 0 1 1 1 0]\n",
      " [1 0 1 1 1 1]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 0 0 0 1]\n",
      " [1 1 0 0 1 0]\n",
      " [1 1 0 0 1 1]\n",
      " [1 1 0 1 0 0]\n",
      " [1 1 0 1 0 1]\n",
      " [1 1 0 1 1 0]\n",
      " [1 1 0 1 1 1]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 1 0 0 1]\n",
      " [1 1 1 0 1 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 1 1 1 0 0]\n",
      " [1 1 1 1 0 1]\n",
      " [1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1]]\n",
      "\n",
      "Data Phenotypes\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n",
      "\n",
      "Data Headers\n",
      "['A_0' 'A_1' 'R_0' 'R_1' 'R_2' 'R_3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read from CSV file\n",
    "data = pd.read_csv(\"Datasets/Real/Multiplexer6.csv\")\n",
    "\n",
    "#Specify the dataset's phenotype label\n",
    "classLabel = \"class\"\n",
    "\n",
    "#Derive the attribute and phenotype array using the phenotype label\n",
    "dataFeatures = data.drop(classLabel,axis = 1).values\n",
    "dataPhenotypes = data[classLabel].values\n",
    "\n",
    "#Optional: Retrieve the headers for each attribute as a length n array\n",
    "dataHeaders = data.drop(classLabel,axis=1).columns.values\n",
    "\n",
    "print(\"Data Features\")\n",
    "print(dataFeatures)\n",
    "print(\"\\nData Phenotypes\")\n",
    "print(dataPhenotypes)\n",
    "print(\"\\nData Headers\")\n",
    "print(dataHeaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another code snippet that uses the same method, but with a dataset that contains missing values. Note that all missing values must be represented as a NaN type when used in the eLCS scikit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features\n",
      "[[ 1. nan  1.  4.]\n",
      " [ 2.  0.  1. nan]\n",
      " [ 4. nan  1.  2.]\n",
      " [nan  1. nan  1.]\n",
      " [ 6. nan  1.  1.]]\n",
      "\n",
      "Data Phenotypes\n",
      "[1 0 1 0 1]\n",
      "\n",
      "Data Headers\n",
      "['N1' 'N2' 'N3' 'N4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read from CSV file\n",
    "data = pd.read_csv(\"Datasets/Tests/MissingFeatureData.csv\")\n",
    "\n",
    "#Specify the dataset's phenotype label\n",
    "classLabel = \"phenotype\"\n",
    "\n",
    "#Derive the attribute and phenotype array using the phenotype label\n",
    "dataFeatures = data.drop(classLabel,axis = 1).values\n",
    "dataPhenotypes = data[classLabel].values\n",
    "\n",
    "#Optional: Retrieve the headers for each attribute as a length n array\n",
    "dataHeaders = data.drop(classLabel,axis=1).columns.values\n",
    "\n",
    "print(\"Data Features\")\n",
    "print(dataFeatures)\n",
    "print(\"\\nData Phenotypes\")\n",
    "print(dataPhenotypes)\n",
    "print(\"\\nData Headers\")\n",
    "print(dataHeaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data Method 2: Using StringEnumerator\n",
    "\n",
    "Given the 4 requirements for the attribute and phenotype array, not all datasets necessarily satisfy those requirements. For example, a dataset may contain an attribute with values that are colors \"red\", \"green\", \"blue\". Since the eLCS scikit model can only work with numeric data, this dataset would not meet the requirements. Alternatively, a dataset may, for some reason, have missing phenotype data. Since the eLCS scikit model requires that the phenotype array is complete, this dataset would also not meet the requirements.\n",
    "\n",
    "To make things more convenient, included in this package is an auxilliary data type called **String Enumerator** that makes it easy to transform datasets that do not meet the requirements into datasets that do.\n",
    "\n",
    "For example, take the below dummy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features\n",
      "[['male' 1.2 'young']\n",
      " ['female' 0.3 nan]\n",
      " ['female' -0.4 'old']\n",
      " [nan 0.0 'young']]\n",
      "\n",
      "Data Phenotypes\n",
      "['china' nan 'china' 'russia']\n",
      "\n",
      "Data Headers\n",
      "['N1' 'N2' 'N3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read from CSV file\n",
    "data = pd.read_csv(\"Datasets/Tests/StringData2.csv\")\n",
    "\n",
    "#Specify the dataset's phenotype label\n",
    "classLabel = \"phenotype\"\n",
    "\n",
    "#Derive the attribute and phenotype array using the phenotype label\n",
    "dataFeatures = data.drop(classLabel,axis = 1).values\n",
    "dataPhenotypes = data[classLabel].values\n",
    "\n",
    "#Optional: Retrieve the headers for each attribute as a length n array\n",
    "dataHeaders = data.drop(classLabel,axis=1).columns.values\n",
    "\n",
    "print(\"Data Features\")\n",
    "print(dataFeatures)\n",
    "print(\"\\nData Phenotypes\")\n",
    "print(dataPhenotypes)\n",
    "print(\"\\nData Headers\")\n",
    "print(dataHeaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dummy dataset does not come close to meeting the dataset requirements for training. There exist many string types in the attribute and phenotype array, as well as missing phenotype data. Aside from not meeting the requirements, the data headers and phenotype label are not too descriptive. Below StringEnumerator cleans this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features\n",
      "[[ 0.   1.2  1. ]\n",
      " [ 1.  -0.4  0. ]\n",
      " [ nan  0.   1. ]]\n",
      "\n",
      "Data Phenotypes\n",
      "[0. 0. 1.]\n",
      "\n",
      "Data Headers\n",
      "['Gender' 'Numeric' 'Age']\n",
      "\n",
      "Class Label\n",
      "Country\n"
     ]
    }
   ],
   "source": [
    "from DataCleanup import StringEnumerator\n",
    "\n",
    "#Initialize StringEnumerator object with csv filepath and class label.\n",
    "converter = StringEnumerator(\"Datasets/Tests/StringData2.csv\",\"phenotype\")\n",
    "\n",
    "#Change Header Names to be more descriptive using changeHeaderName(currentName,newName)\n",
    "converter.changeHeaderName(\"N1\",\"Gender\")\n",
    "converter.changeHeaderName(\"N2\",\"Numeric\")\n",
    "converter.changeHeaderName(\"N3\",\"Age\")\n",
    "\n",
    "#Change Phenotype Label to be more descriptive using changeClassName(newName)\n",
    "converter.changeClassName(\"Country\")\n",
    "\n",
    "'''\n",
    "Convert attributes to numeric data using either:\n",
    "-addAttributeConverterRandom(headerName):   Given an attribute name, randomly assigns each unique attribute value an\n",
    "                                            integer value from 0 to n-1, where n = # of unique attribute values\n",
    "-addAttributeConverter(headerName,array):   Given an attribute name, and an array of attribute values that will be\n",
    "                                            converted, converter assigns each attribute value an integer value from\n",
    "                                            0 to n-1 in the order of attribute values given in the array, where\n",
    "                                            n = length of array\n",
    "'''\n",
    "converter.addAttributeConverterRandom(\"Gender\")\n",
    "converter.addAttributeConverter(\"Age\",[\"old\",\"young\"])\n",
    "\n",
    "'''\n",
    "Convert phenotypes to numeric data using either\n",
    "-addClassConverter(array)\n",
    "-addClassConverterRandom()\n",
    "Same functionality as the attribute converters\n",
    "'''\n",
    "converter.addClassConverterRandom()\n",
    "\n",
    "#Convert all attributes using convertAllAttributes()\n",
    "converter.convertAllAttributes()\n",
    "\n",
    "#Get arrays using getParams()\n",
    "headers,classLabel,dataFeatures,dataPhenotypes = converter.getParams()\n",
    "\n",
    "print(\"Data Features\")\n",
    "print(dataFeatures)\n",
    "print(\"\\nData Phenotypes\")\n",
    "print(dataPhenotypes)\n",
    "print(\"\\nData Headers\")\n",
    "print(headers)\n",
    "print(\"\\nClass Label\")\n",
    "print(classLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the StringEnumerator mapped all string attributes and phenotypes into numeric types, deleted the instance that was missing phenotype data, and made the data headers and class label more descriptive. Now, the data features and phenotypes are ready for training.\n",
    "\n",
    "The StringEnumerator has 2 additional methods not shown above that can also be powerful in data transformation:\n",
    "<ul>\n",
    "    <li>deleteAttribute(headerName): deletes the specified attribute from all instances in the dataset</li>\n",
    "    <li>deleteAllInstancesWithoutHeaderData(headerName): there may be situations where you only want to use data instances that does not have missing data for a specific attribute. This method deletes all instances who's specified attribute is missing</li>\n",
    "</ul>\n",
    "\n",
    "Even if the dataset satisfies all requirements, StringEnumerator can be used as an easy way to get data in the correct format without needing to use pandas, as shown below:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features\n",
      "[[ 1. nan  1.  4.]\n",
      " [ 2.  0.  1. nan]\n",
      " [ 4. nan  1.  2.]\n",
      " [nan  1. nan  1.]\n",
      " [ 6. nan  1.  1.]]\n",
      "\n",
      "Data Phenotypes\n",
      "[1. 0. 1. 0. 1.]\n",
      "\n",
      "Data Headers\n",
      "['N1' 'N2' 'N3' 'N4']\n"
     ]
    }
   ],
   "source": [
    "converter = StringEnumerator(\"Datasets/Tests/MissingFeatureData.csv\",\"phenotype\")\n",
    "headers,classLabel,dataFeatures,dataPhenotypes = converter.getParams()\n",
    "\n",
    "print(\"Data Features\")\n",
    "print(dataFeatures)\n",
    "print(\"\\nData Phenotypes\")\n",
    "print(dataPhenotypes)\n",
    "print(\"\\nData Headers\")\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, StringEnumerator makes loading data in the correct format easy. It is relatively intuitive to use, and if anything invalid operation were done with it, built in checkers will raise contextually Exceptions to help you correct the error. We will be using it to load data for the rest of this user guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Initializing scikit-learn eLCS Classifier Object\n",
    "\n",
    "### Basic Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eLCS import eLCS\n",
    "\n",
    "model = eLCS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the above will initialize an eLCS classifier object using the default hyperparameters, that is now ready for training. However, in most cases, you would want to modify some hyperparameters to your needs. We list all of the tunable hyperparameters and their descriptions:\n",
    "\n",
    "### Overview of all eLCS initialization parameters and default values\n",
    "\n",
    "| Parameter Name | Requirements | Description | Default Value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| learningIterations | non negative integer | The number of training cycles to run | 10000 |\n",
    "| N | non negative integer | Maximum microclassifier population size (sum of classifier numerosities) | 1000 |\n",
    "| p_spec | float from 0 - 1 | Probability of specifying an attribute during the covering procedure | 0.5 |\n",
    "| nu (v) | float | Power parameter used to determine the importance of high accuracy when calculating fitness | 5 |\n",
    "| chi (X) | float from 0 - 1 | The probability of applying crossover in the GA | 0.8 |\n",
    "| upsilon (u) | float from 0 - 1 | The probability of mutating an allele within an offspring | 0.04 |\n",
    "| theta_GA | non negative float | The GA threshold. The GA is applied in the correct set when the average time (# of iterations) since the last GA in the correct set is greater than theta_GA | 25 |\n",
    "| theta_del | non negative integer | The deletion experience threshold; The calculation of the deletion probability changes once this threshold is passed | 20 |\n",
    "| theta_sub | non negative integer | The subsumption experience threshold | 20 |\n",
    "| acc_sub | float from 0 - 1 | Subsumption accuracy requirement | 0.99 |\n",
    "| beta | float | Learning parameter; Used in calculating average correct set size | 0.2 |\n",
    "| delta | float | Deletion parameter; Used in determining deletion vote calculation | 0.1 |\n",
    "| init_fit | float | The initial fitness for a new classifier (typically very small, approaching but not equal to zero) | 0.01 |\n",
    "| fitnessReduction | float | Initial fitness reduction in GA offspring rules | 0.1 |\n",
    "| doSubsumption | boolean | Determines if subsumption is done in the learning process | True |\n",
    "| selectionMethod | \"tournament\" or \"roulette\" | Determines GA selection method | \"tournament\" |\n",
    "| theta_sel | float from 0 - 1 | The fraction of the correct set to be included in tournament selection | 0.5 |\n",
    "| p_spec | float from 0 - 1 | Probability of specifying an attribute during the covering procedure | 0.5 |\n",
    "| p_spec | float from 0 - 1 | Probability of specifying an attribute during the covering procedure | 0.5 |\n",
    "\n",
    "There also exists a few hyperparameters related to the setup and evaluation of the training process:\n",
    "\n",
    "| Parameter Name | Requirements | Description | Default Value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| evalWhileFit | boolean | Determines if live tracking and evaluation is done during model training | False |\n",
    "| trackingFrequency | non negative integer | Relevant only if evalWhileFit param is true. Conducts accuracy approximations and population measurements every \"trackingFrequency\" iterations. If param == 0, tracking done once every epoch | 0 |\n",
    "| learningCheckpoints | numpy.ndarray of nonnegative integers | Relevant only if evalWhileFit param is true. Conducts detailed evaluation of model performance by finding precise training accuracy at the specified iteration count in the array. Iterations are 0 indexed. | empty numpy ndarray |\n",
    "| discreteAttributeLimit | non negative integer OR \"c\" OR \"d\" | Multipurpose param. If it is a nonnegative integer, discreteAttributeLimit determines the threshold that determines if an attribute will be treated as a continuous or discrete attribute. For example, if discreteAttributeLimit == 10, if an attribute has more than 10 unique values in the dataset, the attribute will be continuous. If the attribute has 10 or less unique values, it will be discrete. Alternatively, discreteAttributeLimit can take the value of \"c\" or \"d\". See next param for this. | 10 |\n",
    "| specifiedAttributes | numpy.ndarray of nonnegative integers of attribute indices | If discreteAttributeLimit == \"c\", attributes specified by index in this param will be continuous and the rest will be discrete. If \"d\", attributes specified by index in this param will be discrete and the rest will be continuous | empty numpy ndarray |\n",
    "| discretePhenotypeLimit | non negative integer OR \"c\" OR \"d\" | Works similarly to discreteAttributeLimit. Multipurpose param. If it is a nonnegative integer, this param determines the continuous/discrete threshold for the phenotype. If it is \"c\" or \"d\", the phenotype is explicitly defined as continuous or discrete. For training to occur, the phenotype MUST be discrete | 10 |\n",
    "| randomSeed | integer OR \"none\" | Set a constant random seed value to some integer (in order to obtain reproducible results). Put 'none' if none (pseudo-random algorithm runs) | \"none\" |\n",
    "\n",
    "These hyperparameters can be set during initialization. There exists built in parameter checking to ensure each specified parameter is valid. Below is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eLCS(learningIterations = 5000,evalWhileFit = True,trackingFrequency = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Training and Testing\n",
    "\n",
    "### model.fit(X, y) and how it works\n",
    "Once the model is initialized with the hyperparameters you want, you can train the model by calling the fit(X,y) method, where X is the numpy.ndarray of attributes and y is the numpy.ndarray of phenotypes. Be sure both X and y satisfy the requirements specified in Part 1, or the parameter checker will raise an Exception. Below we demo the entire process of importing relevant packages, loading data, model initialization, and model training using the complete 6 bit multiplexer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eLCS(N=1000, acc_sub=0.99, beta=0.2, chi=0.8, delta=0.1,\n",
       "   discreteAttributeLimit=10, discretePhenotypeLimit=10,\n",
       "   doSubsumption=True, evalWhileFit=False, fitnessReduction=0.1,\n",
       "   init_fit=0.01, learningCheckpoints=array([4999.]),\n",
       "   learningIterations=5000, nu=5, p_spec=0.5, randomSeed='none',\n",
       "   selectionMethod='tournament',\n",
       "   specifiedAttributes=array([], dtype=float64), theta_GA=25, theta_del=20,\n",
       "   theta_sel=0.5, theta_sub=20, trackingFrequency=64, upsilon=0.04)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DataCleanup import StringEnumerator\n",
    "from eLCS import eLCS\n",
    "import numpy as np\n",
    "\n",
    "converter = StringEnumerator(\"Datasets/Real/Multiplexer6.csv\",\"class\")\n",
    "headers,classLabel,dataFeatures,dataPhenotypes = converter.getParams()\n",
    "\n",
    "formatted = np.insert(dataFeatures,dataFeatures.shape[1],dataPhenotypes,1)\n",
    "np.random.shuffle(formatted)\n",
    "dataFeatures = np.delete(formatted,-1,axis=1)\n",
    "dataPhenotypes = formatted[:,-1]\n",
    "\n",
    "model = eLCS(learningIterations = 5000)\n",
    "trainedModel = model.fit(dataFeatures,dataPhenotypes)\n",
    "\n",
    "trainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function returns a trained model. Below we describe the entire training process:\n",
    "\n",
    "<ul>\n",
    "    <li> Step 1: Model verifies X and y are numeric, and that y has no missing values. If not, an Exception is raised. </li>\n",
    "    <li> Step 2: Model performs analysis on X and y. Using the discreteAttributeLimit and specifiedAttributes parameters, it determines and enumerates which attributes are discrete and which attributes are continuous. Using the discretePhenotypeLimit param, it determines whether the phenotype is discrete or continuous. If the phenotype is found to be continuous, the model will raise an Exception. </li>\n",
    "    <li> Step 3: Model completes the specified number of training iterations. If evalWhileFit is True, during the training process, performance data will be collected and stored for later analysis (specified in depth in Part 4). Below is a simplified diagram of the training cycle</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"LearningCycle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.predict(X), model.predict_proba(X), and model.score(X,y)\n",
    "\n",
    "Once the model has finished training, you can call the predict(X) method to return an numpy.ndarray of class predictions given an array of unlabelled instances. The predict method works by using the final rule population of the model to vote on the most probable class based on classifier fitness and numerosity. Before making a prediction, parameter checkers again ensure X is a valid input (fully numeric numpy.ndarray). We refer back to the trained model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedModel.predict(dataFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call the predict_proba(X) method to return an nxm numpy.ndarray of phenotype probabilities, where n = number of data instance and m = number of distinct discrete phenotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'eLCS' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6594deea8c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'eLCS' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "trainedModel.predict_proba(dataFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also score the predictions by calling the score(X,y) method, where X is the unlabelled test data and y is associated list of correct class labels. By default, score(X,y) uses balanced accuracy to score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel.score(dataFeatures,dataPhenotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and Scoring\n",
    "Instead of using predict and score, you can perform a quick cross validation on the model. Below we will run a 3 fold CV on the trained multipler model from above. Again, by default, balanced accuracy is used to score each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "np.mean(cross_val_score(trainedModel,dataFeatures,dataPhenotypes,cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to use a scoring method other than balanced accuracy (e.g. accuracy_score, precision_score, recall_score, f1_score), that can be specified as well via the standard scoring parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(trainedModel,dataFeatures,dataPhenotypes,cv=3,scoring=\"recall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.predict_proba(x) and ROC/AUC/PRC curves\n",
    "\n",
    "TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Data Collection and Export\n",
    "\n",
    "### evalWhileFit, trackingFrequency, learningCheckpoints\n",
    "As mentioned in Part 2, there exists parameters **evalWhileFit**, **trackingFrequency**, and **learningCheckpoints** that determines evaluation during the training process.\n",
    "\n",
    "**evalWhileFit** is a boolean that determines whether evaluation is done during training or not. The benefit to doing evaluation during training is that you will be able to collect data on how the rule population and general statistics of the model changes over many iterations. The downside to doing evaluation during training is that evaluation always slows down the training process, the amount dependent on how much evaluation is being done.\n",
    "\n",
    "If evalWhileFit is True, then the trackingFrequency and learningCheckpoint parameters become relevant. These two parameters determine two kinds of data tracking.\n",
    "\n",
    "**trackingFrequency**: Even if evalWhileFit is true, at the end of every iteration, this following information is saved:\n",
    "<ul>\n",
    "    <li>Macropopulation size</li>\n",
    "    <li>Micropopulation size</li>\n",
    "    <li>Match set size</li>\n",
    "    <li>Correct set size</li>\n",
    "    <li>Average iteration age (experience) of classifiers in correct set</li>\n",
    "    <li>Number of classifiers subsumed in iteration</li>\n",
    "    <li>Number of crossover operations performed in iteration (GA operation)</li>\n",
    "    <li>Number of mutation operations performed in iteration (GA operation)</li>\n",
    "    <li>Number of covering operations performed in iteration</li>\n",
    "    <li>Number of macroclassifiers deleted in iteration</li>\n",
    "    <li>Total training time</li>\n",
    "    <li>Total matching time</li>\n",
    "    <li>Total deletion time</li>\n",
    "    <li>Total subsumption time</li>\n",
    "    <li>Total selection time</li>\n",
    "    <li>Total evaluation time</li>\n",
    "</ul>\n",
    "\n",
    "trackingFrequency thus determines the frequency at which 2 additional pieces of information are collected in addition to the already collected data above:\n",
    "<ul>\n",
    "    <li>Approximate Accuracy</li>\n",
    "    <li>Average Population Generality</li>\n",
    "</ul>\n",
    "This distinction is made because approximate accuracy and average population generality are statistics that are time intensive to compute, and thus not included by default in every iteration.\n",
    "\n",
    "If trackingFrequency == 100 for example, then these two statistics would be collected once every 100 iterations. If trackingFrequnecy == 0 (the default value), then these two statistics would be collected once every epoch.\n",
    "\n",
    "**learningCheckpoints**: learningCheckpoints is a numpy.ndarray that specifies at what iterations a complete training evaluation of the rule population should be completed. Note: iterations are always zero indexed (so the first iteration is enumerated as iteration 0). By default, if evalWhileFit is True, the only learningCheckpoint is the final iteration, where a complete training evaluation is completed on the final rule population. However, evaluations can be done as frequently as specified.\n",
    "\n",
    "At each evaluation, the following data is saved:\n",
    "<ul>\n",
    "    <li> Training Accuracy </li>\n",
    "    <li> Instance Coverage </li>\n",
    "    <li> The complete rule population at the end of that iteration </li>\n",
    "</ul>\n",
    "\n",
    "All of the aforementioned data is saved within an IterationRecord object, under the **record** attribute of the scikit eLCS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting and Accessing Iteration Tracking Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
