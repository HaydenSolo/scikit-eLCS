{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Performance of scikit-eLCS and the Original eLCS Algorithm\n",
    "\n",
    "Author: Robert Zhang - Univeresity of Pennsylvania, B.S.E Computer Science, B.S.E. Economics (SEAS '22, WH '22)\n",
    "\n",
    "Advisor: Ryan Urbanowicz, PhD - University of Pennsylvania, Department of Biostatics, Epidemiology, and Informatics & Institue for Biomedical Informatics (IBI)\n",
    "\n",
    "Date: 04/05/2020\n",
    "\n",
    "Notebook Requirements: (Python 3)\n",
    "<ul>\n",
    "    <li>scikit-eLCS</li>\n",
    "    <li>pandas</li>\n",
    "    <li>numpy</li>\n",
    "    <li>scipy</li>\n",
    "    <li>scikit-learn</li>\n",
    "    <li>matplotlib</li>\n",
    "</ul>\n",
    "\n",
    "## Introduction\n",
    "This notebook presents a comparison between the performance of the original eLCS Algorithm, as presented in the 2017 textbook \"Introduction to Learning Classifier Systems\" by Ryan Urbanowicz and Will Browne, and the new scikit-eLCS Python package.\n",
    "\n",
    "The scikit-eLCS package is a sklearn compatible Python implementation of the original eLCS Algorithm. It was designed to perform equally well in terms of training/testing accuracy and training time, while being significantly more user friendly, and including an array of additional real time & post-training analysis tools. This notebook will demonstrate these capabilities in detail.\n",
    "\n",
    "The scikit-eLCS source code and a complete walkthrough of its usage can be found at <a href=https://github.com/UrbsLab/scikit-eLCS>this Github Repository</a>. The package can be installed via **pip3 install scikit-eLCS**.\n",
    "\n",
    "This notebook uses a slightly modified version of the original eLCS algorithm to improve useability, clarity, and to make it perform (runtime wise) more similar to the scikit-eLCS package, which would run slightly faster otherwise due to its lack of mandatory evaluation, printing, and exporting during training. Thus, this notebook is only comparing the runtime of the core algorithm implementations, rather than evaluating the runtimes of the two packages as a whole.\n",
    "<ul>\n",
    "    <li>Removed from original eLCS all print statements</li>\n",
    "    <li>Removed from original eLCS all obligatory evaluation procedures during training</li>\n",
    "    <li>Removed from original eLCS all export functionality during training</li>\n",
    "    <li>Made training accuracy easier to access for original eLCS</li>\n",
    "    <li>Removed the need for a config file (used param passing instead)</li>\n",
    "    <li>Removed the need for both a test and train file, and made all files csv's instead of txt's</li>\n",
    "</ul>\n",
    "\n",
    "## Notebook Organization\n",
    "**Part 0: Setting Up Some Helper Methods**\n",
    "\n",
    "**Part 1: Comparing Training Accuracy and Runtime**\n",
    "<ul>\n",
    "    <li> 6-bit Multiplexer Problem </li>\n",
    "    <li> 11-bit Multiplexer Problem </li>\n",
    "    <li> 20-bit Multiplexer Problem </li>\n",
    "</ul>\n",
    "\n",
    "**Part 2: Comparing Testing Accuracy**\n",
    "<ul>\n",
    "    <li> 6-bit Multiplexer Problem </li>\n",
    "    <li> 11-bit Multiplexer Problem </li>\n",
    "    <li> 20-bit Multiplexer Problem </li>\n",
    "</ul>\n",
    "\n",
    "**Part 3: Quick Demo of Additional Analysis Tools Provided by scikit-eLCS**\n",
    "<ul>\n",
    "    <li> Iteration Tracking Tool </li>\n",
    "    <li> Rule Population Tool </li>\n",
    "    <li> Population Statistics Tools </li>\n",
    "</ul>\n",
    "\n",
    "## Part 0: Setting Up Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eLCS_Timer import Timer\n",
    "from eLCS_ParamParser import ParamParser\n",
    "from eLCS_Offline_Environment import Offline_Environment\n",
    "from eLCS_Algorithm import eLCS\n",
    "from eLCS_Constants import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def runOriginaleLCS(dataFile,learningIterations,N,randomSeed,labelPhenotype=\"Class\",nu=10,cv=False):\n",
    "    #Run the e-LCS algorithm.\n",
    "    if cv == False:\n",
    "        ParamParser(dataFile,cv=cv,N=N,nu=nu,labelPhenotype=labelPhenotype,learningIterations=learningIterations,randomSeed=randomSeed)\n",
    "        timer = Timer() \n",
    "        cons.referenceTimer(timer)\n",
    "        env = Offline_Environment()\n",
    "        cons.referenceEnv(env)\n",
    "        cons.parseIterations()\n",
    "        e = eLCS()\n",
    "        return np.array([e.trainEval[0],cons.timer.globalTime])\n",
    "    else:\n",
    "        l = []\n",
    "        ParamParser(dataFile,cv=cv,N=N,nu=nu,labelPhenotype=labelPhenotype,learningIterations=learningIterations,randomSeed=randomSeed)\n",
    "        for i in range(cv):\n",
    "            cons.setCV()\n",
    "            timer = Timer() \n",
    "            cons.referenceTimer(timer)\n",
    "            env = Offline_Environment()\n",
    "            cons.referenceEnv(env)\n",
    "            cons.parseIterations()\n",
    "            e = eLCS()\n",
    "            l.append(e.testEval[0])\n",
    "        return np.mean(np.array(l))\n",
    "\n",
    "import skeLCS\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def runScikiteLCS(dataFile,learningIterations,N,random_state,classLabel=\"Class\",nu=10,cv=False):\n",
    "    data = pd.read_csv(dataFile)\n",
    "    dataFeatures = data.drop(classLabel,axis=1).values\n",
    "    dataPhenotypes = data[classLabel].values\n",
    "    model = skeLCS.eLCS(learningIterations = learningIterations,random_state = random_state,N=N,nu=nu)\n",
    "\n",
    "    if cv == False:\n",
    "        model.fit(dataFeatures,dataPhenotypes)\n",
    "        score = model.score(dataFeatures,dataPhenotypes)\n",
    "        return np.array([score,model.timer.globalTime])\n",
    "    else:\n",
    "        formatted = np.insert(dataFeatures,dataFeatures.shape[1],dataPhenotypes,1)\n",
    "        np.random.shuffle(formatted)\n",
    "        dataFeatures = np.delete(formatted,-1,axis=1)\n",
    "        dataPhenotypes = formatted[:,-1]\n",
    "        return np.mean(cross_val_score(model,dataFeatures,dataPhenotypes,cv=cv))\n",
    "\n",
    "randomSeeds = []\n",
    "repeatCount = 1\n",
    "for i in range(repeatCount):\n",
    "    randomSeeds.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Comparing Training Accuracy and Runtime\n",
    "We will use the n-bit Multiplexer Problem to test the training accuracy and runtime of the two eLCS implementations. The Multiplexer Problem is a benchmark LCS problem, due to its highly epistatic and heterogeneous nature.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"MP.jpg\">\n",
    "\n",
    "We will use the same hyperparameters for both eLCS implementations, and also use the same random seed, to ensure the exact replicability (without a set random seed however, the results of analysis will still yield highly similar conclusions).\n",
    "\n",
    "We will use a 500 instance dataset of the 6-bit multiplexer (i.e. there exists duplicate instances), with a maximium micropopulation of 500, with a nu = 10, over 10000 learning iterations.\n",
    "\n",
    "We will use a 5000 instance dataset of the 11-bit multiplexer (i.e. there exists duplicate instances), with a maximium micropopulation of 1000, with a nu = 10, over 10000 learning iterations.\n",
    "\n",
    "We will use a 10000 instance dataset of the 20-bit multiplexer, with a maximium micropopulation of 2000, with a nu = 10, over 10000 learning iterations.\n",
    "\n",
    "### 6-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'discreteAttributeLimit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e16aa97e29a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbit6TrAccO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandomSeeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtoAdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunOriginaleLCS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datasets/Multiplexer6.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'10000'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbit6TimeO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoAdd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbit6TrAccO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoAdd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-35c94cb45d6c>\u001b[0m in \u001b[0;36mrunOriginaleLCS\u001b[0;34m(dataFile, learningIterations, N, randomSeed, labelPhenotype, nu, cv)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Run the e-LCS algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mParamParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelPhenotype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelPhenotype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearningIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningIterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandomSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/1 Academics/Penn/Freshman/FreshmanSummer/PURM/scikit-eLCS/eLCSPerformanceTests/eLCS_ParamParser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataFile, cv, learningIterations, trackingFrequency, N, p_spec, discrete_attribute_limit, nu, chi, upsilon, theta_GA, theta_del, theta_sub, acc_sub, beta, delta, init_fit, fitnessReduction, doSubsumption, selectionMethod, theta_sel, randomSeed, labelInstanceID, labelPhenotype, labelMissingData, doPopulationReboot, popRebootPath)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cv'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataFile'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetConstants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Store run parameters in the 'Constants' module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google_Drive/1 Academics/Penn/Freshman/FreshmanSummer/PURM/scikit-eLCS/eLCSPerformanceTests/eLCS_Constants.py\u001b[0m in \u001b[0;36msetConstants\u001b[0;34m(self, par)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelPhenotype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labelPhenotype'\u001b[0m\u001b[0;34m]\u001b[0m                             \u001b[0;31m#Saved as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMissingData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labelMissingData'\u001b[0m\u001b[0;34m]\u001b[0m                         \u001b[0;31m#Saved as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscreteAttributeLimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'discreteAttributeLimit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#Saved as integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackingFrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trackingFrequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m#Saved as integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'discreteAttributeLimit'"
     ]
    }
   ],
   "source": [
    "avgOriginal = np.array([0,0])\n",
    "bit6TimeO = []\n",
    "bit6TrAccO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer6.csv','10000',500,seed)\n",
    "    bit6TimeO.append(toAdd[1])\n",
    "    bit6TrAccO.append(toAdd[0])\n",
    "    avgOriginal = np.add(avgOriginal,toAdd)\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgOriginal[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgOriginal[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-bit Multiplexeer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = np.array([0,0])\n",
    "bit6TimeS = []\n",
    "bit6TrAccS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer6.csv',10000,500,seed)\n",
    "    bit6TimeS.append(toAdd[1])\n",
    "    bit6TrAccS.append(toAdd[0])\n",
    "    avgScikit = np.add(avgScikit,toAdd)\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgScikit[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgScikit[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgOriginal = np.array([0,0])\n",
    "bit11TimeO = []\n",
    "bit11TrAccO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer11.csv','10000',1000,seed)\n",
    "    bit11TimeO.append(toAdd[1])\n",
    "    bit11TrAccO.append(toAdd[0])\n",
    "    avgOriginal = np.add(avgOriginal,toAdd)\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgOriginal[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgOriginal[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-bit Multiplexer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = np.array([0,0])\n",
    "bit11TimeS = []\n",
    "bit11TrAccS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer11.csv',10000,1000,seed)\n",
    "    bit11TimeS.append(toAdd[1])\n",
    "    bit11TrAccS.append(toAdd[0])\n",
    "    avgScikit = np.add(avgScikit,toAdd)\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgScikit[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgScikit[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgOriginal = np.array([0,0])\n",
    "bit20TimeO = []\n",
    "bit20TrAccO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer20.csv','10000',2000,seed)\n",
    "    bit20TimeO.append(toAdd[1])\n",
    "    bit20TrAccO.append(toAdd[0])\n",
    "    avgOriginal = np.add(avgOriginal,toAdd)\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgOriginal[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgOriginal[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-bit Multiplexer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = np.array([0,0])\n",
    "bit20TimeS = []\n",
    "bit20TrAccS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer20.csv',10000,2000,seed)\n",
    "    bit20TimeS.append(toAdd[1])\n",
    "    bit20TrAccS.append(toAdd[0])\n",
    "    avgScikit = np.add(avgScikit,toAdd)\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Training Accuracy: \"+str(avgScikit[0]))\n",
    "print(\"Average Total Training Time: \"+str(avgScikit[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results\n",
    "Boxplots of Average Training Time and Average Training Accuracy with 6-bit, 11-bit, 20-bit multiplexer problems. Mann-Whitney U Tests for all 6 sets of data.\n",
    "\n",
    "**Average Training Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,axes = plt.subplots(ncols=3,sharey=True)\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "A = [bit6TimeO,bit6TimeS]\n",
    "B = [bit11TimeO,bit11TimeS]\n",
    "C = [bit20TimeO,bit20TimeS]\n",
    "data = {}\n",
    "data['6-bit'] = A\n",
    "data['11-bit'] = B\n",
    "data['20-bit'] = C\n",
    "\n",
    "for ax,name in zip(axes,['6-bit','11-bit','20-bit']):\n",
    "    ax.boxplot([data[name][item] for item in [0, 1]])\n",
    "    ax.set(xticklabels=['Original', 'scikit'], xlabel=name)\n",
    "    ax.margins(0.05) # Optional\n",
    "    if name == '6-bit':\n",
    "        ax.set_ylabel('Training Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Training Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(ncols=3,sharey=True)\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "A = [bit6TrAccO,bit6TrAccS]\n",
    "B = [bit11TrAccO,bit11TrAccS]\n",
    "C = [bit20TrAccO,bit20TrAccS]\n",
    "\n",
    "data = {}\n",
    "data['6-bit'] = A\n",
    "data['11-bit'] = B\n",
    "data['20-bit'] = C\n",
    "\n",
    "for ax,name in zip(axes,['6-bit','11-bit','20-bit']):\n",
    "    ax.boxplot([data[name][item] for item in [0, 1]])\n",
    "    ax.set(xticklabels=['Original', 'scikit'], xlabel=name)\n",
    "    ax.margins(0.05) # Optional\n",
    "    if name == '6-bit':\n",
    "        ax.set_ylabel('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mann-Whitney U Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def domannwhitneyu(d1,d2):\n",
    "    if np.sum(np.array(d1+d2))/(len(d1+d2)) == d1[0]:\n",
    "        return \"Test Aborted. All distribution values were: \"+str(d1[0])\n",
    "    else:\n",
    "        return mannwhitneyu(d1,d2)[1]\n",
    "\n",
    "print(\"6-bit Multiplexer training time (p-value):\"+str(domannwhitneyu(bit6TimeO,bit6TimeS)))\n",
    "print(\"11-bit Multiplexer training time (p-value):\"+str(domannwhitneyu(bit11TimeO,bit11TimeS)))\n",
    "print(\"20-bit Multiplexer training time (p-value):\"+str(domannwhitneyu(bit20TimeO,bit20TimeS)))\n",
    "print(\"6-bit Multiplexer training accuracy (p-value):\"+str(domannwhitneyu(bit6TrAccO,bit6TrAccS)))\n",
    "print(\"11-bit Multiplexer training accuracy (p-value):\"+str(domannwhitneyu(bit11TrAccO,bit11TrAccS)))\n",
    "print(\"20-bit Multiplexer training accuracy (p-value):\"+str(domannwhitneyu(bit20TrAccO,bit20TrAccS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Comparing Testing Accuracy\n",
    "We will conduct a 3-fold CV 5 times (for 5 random seeds) for the 3 Multiplexer Problems above\n",
    "\n",
    "### 6-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgOriginal = 0\n",
    "bit6TestO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer6.csv','10000',500,seed,cv=3)\n",
    "    bit6TestO.append(toAdd)\n",
    "    avgOriginal += toAdd\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgOriginal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-bit Multiplexer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = 0\n",
    "bit6TestS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer6.csv',10000,500,seed,cv=3)\n",
    "    bit6TestS.append(toAdd)\n",
    "    avgScikit += toAdd\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgScikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgOriginal = 0\n",
    "bit11TestO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer11.csv','10000',1000,seed,cv=3)\n",
    "    bit11TestO.append(toAdd)\n",
    "    avgOriginal += toAdd\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgOriginal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-bit Multiplexer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = 0\n",
    "bit11TestS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer11.csv',10000,1000,seed,cv=3)\n",
    "    bit11TestS.append(toAdd)\n",
    "    avgScikit += toAdd\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgScikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-bit Multiplexer Problem with Original eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgOriginal = 0\n",
    "bit20TestO = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runOriginaleLCS('Datasets/Multiplexer20.csv','10000',2000,seed,cv=3)\n",
    "    bit20TestO.append(toAdd)\n",
    "    avgOriginal += toAdd\n",
    "avgOriginal /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgOriginal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-bit Multiplexer Problem with scikit-eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgScikit = 0\n",
    "bit20TestS = []\n",
    "for seed in randomSeeds:\n",
    "    toAdd = runScikiteLCS('Datasets/Multiplexer20.csv',10000,2000,seed,cv=3)\n",
    "    bit20TestS.append(toAdd)\n",
    "    avgScikit += toAdd\n",
    "avgScikit /= repeatCount\n",
    "\n",
    "print(\"Average Testing Accuracy: \"+str(avgScikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results\n",
    "Boxplots of Average Testing Accuracy with 6-bit, 11-bit, 20-bit multiplexer problems. Mann-Whitney U Tests for all 3 sets of data.\n",
    "\n",
    "**Average Testing Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(ncols=3,sharey=True)\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "A = [bit6TestO,bit6TestS]\n",
    "B = [bit11TestO,bit11TestS]\n",
    "C = [bit20TestO,bit20TestS]\n",
    "\n",
    "data = {}\n",
    "data['6-bit'] = A\n",
    "data['11-bit'] = B\n",
    "data['20-bit'] = C\n",
    "\n",
    "for ax,name in zip(axes,['6-bit','11-bit','20-bit']):\n",
    "    ax.boxplot([data[name][item] for item in [0, 1]])\n",
    "    ax.set(xticklabels=['Original', 'scikit'], xlabel=name)\n",
    "    ax.margins(0.05) # Optional\n",
    "    if name == '6-bit':\n",
    "        ax.set_ylabel('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mann-Whitney U Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"6-bit Multiplexer testing accuracy (p-value):\"+str(domannwhitneyu(bit6TestO,bit6TestS)))\n",
    "print(\"11-bit Multiplexer testing accuracy (p-value):\"+str(domannwhitneyu(bit11TestO,bit11TestS)))\n",
    "print(\"20-bit Multiplexer testing accuracy (p-value):\"+str(domannwhitneyu(bit20TestO,bit20TestS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Quick Demo of Additional Analysis Tools Provided by scikit-eLCS\n",
    "Aside from performing similarly to the original eLCS, scikit-eLCS provides a suite of learning tracking and evaluation tools that can be enabled and called during and after the training process. A subset of these tools can be found demoed briefly below. A full walkthrough of this tools can be found in the Jupyter Notebook within the <a href=https://github.com/UrbsLab/scikit-eLCS>scikit-eLCS Github repo</a>.\n",
    "\n",
    "### Setup and Training of New scikit-eLCS Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skeLCS.DataCleanup import StringEnumerator\n",
    "from skeLCS.eLCS import eLCS\n",
    "import numpy as np\n",
    "\n",
    "converter = StringEnumerator(\"DataSets/Multiplexer11.csv\",\"Class\")\n",
    "headers,classLabel,dataFeatures,dataPhenotypes = converter.get_params()\n",
    "\n",
    "formatted = np.insert(dataFeatures,dataFeatures.shape[1],dataPhenotypes,1)\n",
    "np.random.shuffle(formatted)\n",
    "dataFeatures = np.delete(formatted,-1,axis=1)\n",
    "dataPhenotypes = formatted[:,-1]\n",
    "\n",
    "model = eLCS(learningIterations = 5000,track_accuracy_while_fit=True)\n",
    "trainedModel = model.fit(dataFeatures,dataPhenotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration Tracking Tool\n",
    "Tracking or certain metrics is done during training. The following information to be saved at every iteration:\n",
    "<ul>\n",
    "    <li>Approximate Accuracy (if track_accuracy_while_fit is True)li>\n",
    "    <li>Macropopulation Size</li>\n",
    "    <li>Micropopulation Size</li>\n",
    "    <li>Match Set Size</li>\n",
    "    <li>Correct Set Size</li>\n",
    "    <li>Average iteration age (experience) of classifiers in correct set</li>\n",
    "    <li>Number of classifiers subsumed in iteration</li>\n",
    "    <li>Number of crossover operations performed in iteration (GA operation)</li>\n",
    "    <li>Number of mutation operations performed in iteration (GA operation)</li>\n",
    "    <li>Number of covering operations performed in iteration</li>\n",
    "    <li>Number of macroclassifiers deleted in iteration</li>\n",
    "    <li>Total training time</li>\n",
    "    <li>Total matching time</li>\n",
    "    <li>Total deletion time</li>\n",
    "    <li>Total subsumption time</li>\n",
    "    <li>Total selection time</li>\n",
    "    <li>Total evaluation time</li>\n",
    "</ul>\n",
    "It also occasionally tracks average rule population generality. After training, as csv of this data can be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel.export_iteration_tracking_data(\"defaultExportDir/iterationData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can then be graphed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cumulativeFreq(freq):\n",
    "    a = []\n",
    "    c = []\n",
    "    for i in freq:\n",
    "        a.append(i+sum(c))\n",
    "        c.append(i)\n",
    "    return np.array(a)\n",
    "\n",
    "def movingAvg(a,threshold=300):\n",
    "    weights = np.repeat(1.0,threshold)/threshold\n",
    "    conv = np.convolve(a,weights,'valid')\n",
    "    return np.append(conv,np.full(threshold-1,conv[conv.size-1]),)\n",
    "\n",
    "dataTracking = pd.read_csv(\"defaultExportDir/iterationData.csv\")\n",
    "\n",
    "iterations = dataTracking[\"Iteration\"].values\n",
    "accuracy = dataTracking['Accuracy (approx)'].values\n",
    "generality = dataTracking['Average Population Generality'].values\n",
    "macroPop = dataTracking[\"Macropopulation Size\"].values\n",
    "microPop = dataTracking[\"Micropopulation Size\"].values\n",
    "mSize = dataTracking[\"Match Set Size\"].values\n",
    "cSize = dataTracking[\"Correct Set Size\"].values\n",
    "experience = dataTracking[\"Average Iteration Age of Correct Set Classifiers\"].values\n",
    "subsumption = dataTracking[\"# Classifiers Subsumed in Iteration\"].values\n",
    "crossover = dataTracking[\"# Crossover Operations Performed in Iteration\"].values\n",
    "mutation = dataTracking[\"# Mutation Operations Performed in Iteration\"].values\n",
    "covering = dataTracking[\"# Covering Operations Performed in Iteration\"].values\n",
    "deletion = dataTracking[\"# Deletion Operations Performed in Iteration\"].values\n",
    "\n",
    "gTime = dataTracking[\"Total Global Time\"].values\n",
    "mTime = dataTracking[\"Total Matching Time\"].values\n",
    "delTime = dataTracking[\"Total Deletion Time\"].values\n",
    "subTime = dataTracking[\"Total Subsumption Time\"].values\n",
    "selTime = dataTracking[\"Total Selection Time\"].values\n",
    "evalTime = dataTracking[\"Total Evaluation Time\"].values\n",
    "\n",
    "plt.plot(iterations,accuracy,label=\"approx accuracy\")\n",
    "plt.plot(iterations,generality,label=\"avg generality\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('accuracy/generality')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iterations,macroPop,label=\"macroPop Size\")\n",
    "plt.plot(iterations,microPop,label=\"microPop Size\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Macro/MicroPop Size')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iterations,mSize,label=\"[M] size\")\n",
    "plt.plot(iterations,movingAvg(mSize),label=\"[M] size movingAvg\")\n",
    "plt.plot(iterations,cSize,label=\"[C] size\")\n",
    "plt.plot(iterations,movingAvg(cSize),label=\"[C] size movingAvg\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('[M]/[C] size per iteration')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iterations,experience)\n",
    "plt.ylabel('Average [C] Classifier Age')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iterations,cumulativeFreq(subsumption),label=\"Subsumption Count\")\n",
    "plt.plot(iterations,cumulativeFreq(crossover),label=\"Crossover Count\")\n",
    "plt.plot(iterations,cumulativeFreq(mutation),label=\"Mutation Count\")\n",
    "plt.plot(iterations,cumulativeFreq(deletion),label=\"Deletion Count\")\n",
    "plt.plot(iterations,cumulativeFreq(covering),label=\"Covering Count\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cumulative Operations Count Over Iterations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iterations,mTime,label=\"Matching Time\")\n",
    "plt.plot(iterations,delTime+mTime,label=\"Deletion Time\")\n",
    "plt.plot(iterations,subTime+delTime+mTime,label=\"Subsumption Time\")\n",
    "plt.plot(iterations,selTime+subTime+delTime+mTime,label=\"Selection Time\")\n",
    "plt.plot(iterations,evalTime+selTime+subTime+delTime+mTime,label=\"Evaluation Time\")\n",
    "plt.plot(iterations,gTime,label=\"Total Time\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cumulative Time (Stacked)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Population Tool\n",
    "In addition to iteration tracking, scikit-eLCS allows you to export the rule population of the eLCS estimator at specified iterations (in either DCAL or traditional rule representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel.export_final_rule_population(headers,classLabel,filename=\"defaultExportDir/fileRulePopulation.csv\",DCAL=False)\n",
    "display(pd.read_csv(\"defaultExportDir/fileRulePopulation.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
